{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1400106,"sourceType":"datasetVersion","datasetId":818027}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport cv2\nimport imghdr\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import LabelBinarizer\nfrom itertools import chain\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-25T21:27:40.724353Z","iopub.execute_input":"2023-11-25T21:27:40.724866Z","iopub.status.idle":"2023-11-25T21:27:40.731741Z","shell.execute_reply.started":"2023-11-25T21:27:40.724833Z","shell.execute_reply":"2023-11-25T21:27:40.730339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Loading and visualization Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\ntest = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv')\ntrain_img_dir = '/kaggle/input/handwriting-recognition/train_v2/train'\ntest_img_dir = '/kaggle/input/handwriting-recognition/validation_v2/validation'\ntrain.head(6), test.head(6)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T22:44:21.989216Z","iopub.execute_input":"2023-11-25T22:44:21.989721Z","iopub.status.idle":"2023-11-25T22:44:22.408443Z","shell.execute_reply.started":"2023-11-25T22:44:21.989675Z","shell.execute_reply":"2023-11-25T22:44:22.407456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"##### Remove all rows that have as IDENTITY = UNREADABLE","metadata":{}},{"cell_type":"code","source":"print(\"Tain set: \",train['IDENTITY'].shape[0])\nprint(\"UNREADABLE in train set : \", train['IDENTITY'].isnull().sum())\nprint(\"Test set: \", test['IDENTITY'].shape[0])\nprint(\"UNREADABLE in validation set : \", test['IDENTITY'].isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:41.167798Z","iopub.execute_input":"2023-11-25T21:27:41.168354Z","iopub.status.idle":"2023-11-25T21:27:41.221572Z","shell.execute_reply.started":"2023-11-25T21:27:41.168313Z","shell.execute_reply":"2023-11-25T21:27:41.22006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[train['IDENTITY'] != 'UNREADABLE']\ntrain = train.dropna()\ntest = test[test['IDENTITY'] != 'UNREADABLE']\ntest = test.dropna()\nprint(\"train:\",train.shape[0],\" test:\",test.shape[0])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:41.224791Z","iopub.execute_input":"2023-11-25T21:27:41.225333Z","iopub.status.idle":"2023-11-25T21:27:41.417756Z","shell.execute_reply.started":"2023-11-25T21:27:41.225302Z","shell.execute_reply":"2023-11-25T21:27:41.416482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Transformation data","metadata":{}},{"cell_type":"markdown","source":"#### For model to perform better , it must:\n* Resize all data to one size (in my case i choose [284,62])\n* Convert image from (R,G,B) to binary (1 or 0) ","metadata":{}},{"cell_type":"code","source":"def to_binary(image):\n    image = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB),dsize=(284,62))\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    (thresh, image_binary) = cv2.threshold(image_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n    image_binary = cv2.threshold(image_gray, thresh, 255, cv2.THRESH_BINARY)[1]\n    image_binary = image_binary / 255\n    return image_binary\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:41.420548Z","iopub.execute_input":"2023-11-25T21:27:41.420916Z","iopub.status.idle":"2023-11-25T21:27:41.428158Z","shell.execute_reply.started":"2023-11-25T21:27:41.420886Z","shell.execute_reply":"2023-11-25T21:27:41.427193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data\n* train_data_img   containing all the pictures of train data\n* test_data_img   containing all the pictures of test data\n* train_data_idt   containing all IDENTITY of train data\n* test_data_idt   containing all IDENTITY of test data","metadata":{}},{"cell_type":"code","source":"train_data_img = []\ntrain_data_idt = []\n#for i in range(test.shape[0]):   #it's take too longe to do all images\nfor i in range(1000):\n    image_filename = train['FILENAME'].iloc[i] \n    image_path = os.path.join(train_img_dir,image_filename)\n    image = cv2.imread(image_path)\n    image = to_binary(image)\n    train_data_img.append(image) \n    train_data_idt.append(train['IDENTITY'].iloc[i])    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:41.430035Z","iopub.execute_input":"2023-11-25T21:27:41.430546Z","iopub.status.idle":"2023-11-25T21:27:42.945564Z","shell.execute_reply.started":"2023-11-25T21:27:41.430506Z","shell.execute_reply":"2023-11-25T21:27:42.944252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_img = []\ntest_data_idt = []\n#for i in range(test.shape[0]):\nfor i in range(1000):\n    image_filename = test['FILENAME'].iloc[i]\n    image_path = os.path.join(test_img_dir,image_filename)\n    image = cv2.imread(image_path)\n    image = to_binary(image)\n    test_data_img.append(image)\n    test_data_idt.append(test['IDENTITY'].iloc[i])  \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:42.947444Z","iopub.execute_input":"2023-11-25T21:27:42.947921Z","iopub.status.idle":"2023-11-25T21:27:44.527147Z","shell.execute_reply.started":"2023-11-25T21:27:42.947878Z","shell.execute_reply":"2023-11-25T21:27:44.526112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    print(train_data_idt[i])\n    print(train_data_img[i].shape)\n    plt.imshow(train_data_img[i],cmap='gray')\n    plt.axis('off')\n    plt.show()\nfor i in range(3):\n    print(test_data_idt[i])\n    print(test_data_img[i].shape)\n    plt.imshow(test_data_img[i],cmap='gray')\n    plt.axis('off')\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-25T22:14:08.145501Z","iopub.execute_input":"2023-11-25T22:14:08.145966Z","iopub.status.idle":"2023-11-25T22:14:08.794207Z","shell.execute_reply.started":"2023-11-25T22:14:08.14593Z","shell.execute_reply":"2023-11-25T22:14:08.792622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## coding IDENTITY \n","metadata":{}},{"cell_type":"markdown","source":"#### 1. extract all the letters used in all data (IDENTITY)","metadata":{}},{"cell_type":"code","source":"all_data = train_data_idt + test_data_idt\n# Concatenate names into a single string\nall_characters = ''.join(all_data)\n\n# Create a set to get unique characters\nunique_characters_set = set(all_characters)\n\n# Convert the set back to a list if needed\nunique_characters_list = list(unique_characters_set)\n\nprint(unique_characters_list)\nprint(len(unique_characters_list))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:45.837115Z","iopub.execute_input":"2023-11-25T21:27:45.838556Z","iopub.status.idle":"2023-11-25T21:27:45.851382Z","shell.execute_reply.started":"2023-11-25T21:27:45.838494Z","shell.execute_reply":"2023-11-25T21:27:45.849455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Creat dictionary ","metadata":{}},{"cell_type":"markdown","source":"* Encode each character into vector as {‘a’:[1,0,0,0], ‘b’:[0,1,0,0] …….. ‘z’:[0,0,0,1]} etc. ","metadata":{}},{"cell_type":"code","source":"lb = LabelBinarizer()\nlb.fit(unique_characters_list)\nlb.classes_\ndec = {}\nfor i in range(len(unique_characters_list)):\n    if unique_characters_list[i] in dec.keys():\n        pass\n    else: \n        a = lb.transform([unique_characters_list[i]])\n        a = list(chain(*a)) #flattened_list from [[....]] to []\n        dec[unique_characters_list[i]]= a\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:45.854496Z","iopub.execute_input":"2023-11-25T21:27:45.856739Z","iopub.status.idle":"2023-11-25T21:27:45.905371Z","shell.execute_reply.started":"2023-11-25T21:27:45.856659Z","shell.execute_reply":"2023-11-25T21:27:45.903787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train data longest word :\")\nlength_of_longest_word_in_train = len(max(train_data_idt, key=len))\nprint(length_of_longest_word_in_train)\nword_with_longest_characters = max(train_data_idt, key=len)\nprint(word_with_longest_characters)\nprint()\nprint(\"test data longest word :\")\nlength_of_longest_word_in_test = len(max(test_data_idt, key=len))\nprint(length_of_longest_word_in_test)\nword_with_longest_characters = max(test_data_idt, key=len)\nprint(word_with_longest_characters)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:45.911987Z","iopub.execute_input":"2023-11-25T21:27:45.913438Z","iopub.status.idle":"2023-11-25T21:27:45.924761Z","shell.execute_reply.started":"2023-11-25T21:27:45.913365Z","shell.execute_reply":"2023-11-25T21:27:45.923791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. coding all IDENTITY using our dictionary  \n","metadata":{}},{"cell_type":"code","source":"\n# Function to convert a name to a list of vectors using the dictionary\ndef name_to_vectors(name,max_len,num_char):\n    zeros_list = [0] * num_char\n    num_vec_to_add = max_len - len(name)\n    list_vc_name = [dec[char] for char in name]\n    \n    for i in range(num_vec_to_add):\n        list_vc_name.append(zeros_list)\n    return list_vc_name\n\n# Creating a list of vectors for each name\nvectors_list_train_idt = [name_to_vectors(name,length_of_longest_word_in_train,len(unique_characters_list)) for name in train_data_idt] # for train data\nvectors_list_test_idt = [name_to_vectors(name,length_of_longest_word_in_train,len(unique_characters_list)) for name in test_data_idt] # for test data \n\n#for name, vectors in zip(names, vectors_list):\n    #print(f\"{name}: {vectors}\")\nvectors_list_train_idt = np.array(vectors_list_train_idt) #change from list to numpy array\nvectors_list_test_idt = np.array(vectors_list_test_idt)\nprint(vectors_list_train_idt.shape)\nprint(vectors_list_test_idt.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:45.926471Z","iopub.execute_input":"2023-11-25T21:27:45.92689Z","iopub.status.idle":"2023-11-25T21:27:46.078997Z","shell.execute_reply.started":"2023-11-25T21:27:45.926856Z","shell.execute_reply":"2023-11-25T21:27:46.077957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LB = LabelBinarizer()\n#train_data_idt = LB.fit_transform(train_data_idt)\n#test_data_idt = LB.fit_transform(test_data_idt)\n#print(test_data_idt[0:5])\n\ntrain_data_img = np.array(train_data_img)\ntrain_data_img = train_data_img.reshape(-1,62,284,1)\n\ntest_data_img = np.array(test_data_img)\ntest_data_img = test_data_img.reshape(-1,62,284,1)\n\n#train_data_idt = np.array(train_data_idt)\n#test_data_idt = np.array(test_data_idt)\n\n#print(type(train_data_idt[1]), type(test_data_idt))\nprint(train_data_img.shape,vectors_list_train_idt.shape)\nprint(test_data_img.shape,vectors_list_test_idt.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:46.08062Z","iopub.execute_input":"2023-11-25T21:27:46.08107Z","iopub.status.idle":"2023-11-25T21:27:46.359083Z","shell.execute_reply.started":"2023-11-25T21:27:46.081037Z","shell.execute_reply":"2023-11-25T21:27:46.357575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Creat model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:46.361249Z","iopub.execute_input":"2023-11-25T21:27:46.361626Z","iopub.status.idle":"2023-11-25T21:27:46.367092Z","shell.execute_reply.started":"2023-11-25T21:27:46.361596Z","shell.execute_reply":"2023-11-25T21:27:46.365436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(62,284,1)))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32, (3,3), 1, activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(16, (3,3), 1, activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(len(unique_characters_list), activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:46.368602Z","iopub.execute_input":"2023-11-25T21:27:46.369074Z","iopub.status.idle":"2023-11-25T21:27:46.480788Z","shell.execute_reply.started":"2023-11-25T21:27:46.369027Z","shell.execute_reply":"2023-11-25T21:27:46.479695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:46.482134Z","iopub.execute_input":"2023-11-25T21:27:46.482453Z","iopub.status.idle":"2023-11-25T21:27:46.496732Z","shell.execute_reply.started":"2023-11-25T21:27:46.482426Z","shell.execute_reply":"2023-11-25T21:27:46.495453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:46.498339Z","iopub.execute_input":"2023-11-25T21:27:46.498678Z","iopub.status.idle":"2023-11-25T21:27:46.539154Z","shell.execute_reply.started":"2023-11-25T21:27:46.498651Z","shell.execute_reply":"2023-11-25T21:27:46.537835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train_data_img shape:\", train_data_img.shape)\nprint(\"vectors_list_train_idt shape:\", vectors_list_train_idt.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:46.540499Z","iopub.execute_input":"2023-11-25T21:27:46.540931Z","iopub.status.idle":"2023-11-25T21:27:46.547413Z","shell.execute_reply.started":"2023-11-25T21:27:46.540888Z","shell.execute_reply":"2023-11-25T21:27:46.546274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vectors_list_train_idt = vectors_list_train_idt.reshape(-1, len(unique_characters_list))\n#vectors_list_test_idt = vectors_list_test_idt.reshape(-1, len(unique_characters_list))\n\n#history = model.fit(train_data_img, vectors_list_train_idt, epochs=20, batch_size=8, validation_data=(test_data_img, vectors_list_test_idt), verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T21:27:46.549352Z","iopub.execute_input":"2023-11-25T21:27:46.549775Z","iopub.status.idle":"2023-11-25T21:27:46.836475Z","shell.execute_reply.started":"2023-11-25T21:27:46.549704Z","shell.execute_reply":"2023-11-25T21:27:46.83476Z"},"trusted":true},"execution_count":null,"outputs":[]}]}